{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "This notebook handles, preprocessing of raw data which is to be used for training and validating models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Preprocess Sentinel-1 Data\n",
    "\n",
    "Query the Sentinel-1 Data buckets:\n",
    " - Query S3 storage for general area and time of interest\n",
    " - Clip to region of interests (wetlands)\n",
    " - Clamp values to reduce noise  - data investigation determined a range of [0, 200]\n",
    " - Coarsen raster data so our models don't get too big - no GPUs atm\n",
    " - Save as int16 -> sufficient precision as we raw data is stored in int16 as well, and we don't add info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Load S1-Datasets and Ramsar Geometry\n",
    "\n",
    "Load the S1 datasets in the time and region of interest as well as the Ramsar shape files containing the geometry of the wetlands.\n",
    "\n",
    "**NOTE:** We use VH for now, as the reduced noise should help training machine learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from rattlinbog.loaders import load_s1_datasets_from_file_list, load_rois, DATE_FORMAT\n",
    "from pathlib import Path\n",
    "\n",
    "S1_2021_AT_FILE_LIST = Path(\"/shared/sentinel-1/paths-west-AT-2021.txt\")\n",
    "RAMSAR_SHAPE_FILE = Path(\"/shared/ramsar/RAMSAR_AT_01.shp\")\n",
    "\n",
    "vh_datasets = load_s1_datasets_from_file_list(S1_2021_AT_FILE_LIST, bands={'VH'})\n",
    "ramsar_rois = load_rois(RAMSAR_SHAPE_FILE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Sentinel-1 data reduction\n",
    "\n",
    "To apply our models efficiently we want to reduce the data\n",
    "- Clip to our specific Ramsar regions of interest\n",
    "- Clamp data to reduce noise\n",
    "- Coarsen the resolution - speeding up training of machine learning models and reducing noise\n",
    "- Round to int16 - this precision should be sufficient\n",
    "- Stream to shared disk for further usage"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ramsar_rois= [r for r in ramsar_rois if \"Donau\" in r.name]\n",
    "ramsar_rois"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from xarray import Dataset\n",
    "from rattlinbog.data_group import group_datasets, GroupByRois\n",
    "from rattlinbog.transforms import Compose, ClipRoi, ConcatTimeSeries, ClipValues, CoarsenAvgSpatially, RoundToInt16, \\\n",
    "    StoreAsNetCDF, NameDatasets, EatMyData\n",
    "\n",
    "S1_2021_100m_OUT = Path(\"/shared/sentinel-1/roi/100m\")\n",
    "\n",
    "\n",
    "def ds_namer(ds: Dataset) -> str:\n",
    "    time_str = ds.attrs['time'].strftime(DATE_FORMAT)\n",
    "    roi_name = ds.attrs['roi'].name.replace(' ', '_')\n",
    "    return f\"{time_str}_{roi_name}\"\n",
    "\n",
    "\n",
    "transformation_pipeline = Compose([ClipRoi(),\n",
    "                                   ClipValues(vmin=0, vmax=200),\n",
    "                                   CoarsenAvgSpatially(stride=10),\n",
    "                                   ConcatTimeSeries(),\n",
    "                                   RoundToInt16(),\n",
    "                                   NameDatasets(ds_namer),\n",
    "                                   StoreAsNetCDF(S1_2021_100m_OUT),\n",
    "                                   EatMyData()])\n",
    "group = group_datasets(vh_datasets, by_rule=GroupByRois(ramsar_rois))\n",
    "group = transformation_pipeline(group)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"transform successful\")\n",
    "group"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Sentinel-1 data reduction\n",
    "\n",
    "To apply our models efficiently we want to reduce the data\n",
    "- Clip to our specific Ramsar regions of interest\n",
    "- Clamp data to reduce noise\n",
    "- Coarsen the resolution - speeding up training of machine learning models and reducing noise\n",
    "- Round to int16 - this precision should be sufficient\n",
    "- Stream to shared disk for further usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ROI(name='Donau-March-Thaya-Auen', geometry=<shapely.geometry.polygon.Polygon object at 0x7f97b25308b0>)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ramsar_rois= [r for r in ramsar_rois if \"Donau\" in r.name]\n",
    "ramsar_rois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 94.8 GiB for an array with shape (161203, 157857) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mMemoryError\u001B[0m                               Traceback (most recent call last)",
      "Input \u001B[0;32mIn [5]\u001B[0m, in \u001B[0;36m<cell line: 24>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     15\u001B[0m transformation_pipeline \u001B[38;5;241m=\u001B[39m Compose([ClipRoi(),\n\u001B[1;32m     16\u001B[0m                                    ClipValues(vmin\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m, vmax\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m200\u001B[39m),\n\u001B[1;32m     17\u001B[0m                                    CoarsenAvgSpatially(stride\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     21\u001B[0m                                    StoreAsNetCDF(S1_2021_100m_OUT),\n\u001B[1;32m     22\u001B[0m                                    EatMyData()])\n\u001B[1;32m     23\u001B[0m group \u001B[38;5;241m=\u001B[39m group_datasets(vh_datasets, by_rule\u001B[38;5;241m=\u001B[39mGroupByRois(ramsar_rois))\n\u001B[0;32m---> 24\u001B[0m group \u001B[38;5;241m=\u001B[39m \u001B[43mtransformation_pipeline\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgroup\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/code/use-case-wetland-water-stress/rattlinbog/transforms.py:31\u001B[0m, in \u001B[0;36mCompose.__call__\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     29\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, x: DataGroup) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m DataGroup:\n\u001B[1;32m     30\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_transformations:\n\u001B[0;32m---> 31\u001B[0m         x \u001B[38;5;241m=\u001B[39m \u001B[43mt\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     32\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m x\n",
      "File \u001B[0;32m~/code/use-case-wetland-water-stress/rattlinbog/transforms.py:59\u001B[0m, in \u001B[0;36mConcatTimeSeries.__call__\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     57\u001B[0m     sorted_ds \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msorted\u001B[39m(x[k], key\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mlambda\u001B[39;00m d: d\u001B[38;5;241m.\u001B[39mattrs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtime\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m     58\u001B[0m     times \u001B[38;5;241m=\u001B[39m [d\u001B[38;5;241m.\u001B[39mattrs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtime\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m d \u001B[38;5;129;01min\u001B[39;00m sorted_ds]\n\u001B[0;32m---> 59\u001B[0m     x[k] \u001B[38;5;241m=\u001B[39m [\u001B[43mxr\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconcat\u001B[49m\u001B[43m(\u001B[49m\u001B[43msorted_ds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtime\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39massign_coords({\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtime\u001B[39m\u001B[38;5;124m'\u001B[39m: times})]\n\u001B[1;32m     60\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m x\n",
      "File \u001B[0;32m~/miniconda3/envs/ml-wetlands/lib/python3.8/site-packages/xarray/core/concat.py:238\u001B[0m, in \u001B[0;36mconcat\u001B[0;34m(objs, dim, data_vars, coords, compat, positions, fill_value, join, combine_attrs)\u001B[0m\n\u001B[1;32m    233\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    234\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[1;32m    235\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcan only concatenate xarray Dataset and DataArray \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    236\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mobjects, got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(first_obj)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    237\u001B[0m     )\n\u001B[0;32m--> 238\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    239\u001B[0m \u001B[43m    \u001B[49m\u001B[43mobjs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata_vars\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcoords\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcompat\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpositions\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfill_value\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mjoin\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcombine_attrs\u001B[49m\n\u001B[1;32m    240\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/ml-wetlands/lib/python3.8/site-packages/xarray/core/concat.py:438\u001B[0m, in \u001B[0;36m_dataset_concat\u001B[0;34m(datasets, dim, data_vars, coords, compat, positions, fill_value, join, combine_attrs)\u001B[0m\n\u001B[1;32m    435\u001B[0m \u001B[38;5;66;03m# Make sure we're working on a copy (we'll be loading variables)\u001B[39;00m\n\u001B[1;32m    436\u001B[0m datasets \u001B[38;5;241m=\u001B[39m [ds\u001B[38;5;241m.\u001B[39mcopy() \u001B[38;5;28;01mfor\u001B[39;00m ds \u001B[38;5;129;01min\u001B[39;00m datasets]\n\u001B[1;32m    437\u001B[0m datasets \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(\n\u001B[0;32m--> 438\u001B[0m     \u001B[43malign\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mdatasets\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mjoin\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexclude\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mdim\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfill_value\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfill_value\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    439\u001B[0m )\n\u001B[1;32m    441\u001B[0m dim_coords, dims_sizes, coord_names, data_names \u001B[38;5;241m=\u001B[39m _parse_datasets(datasets)\n\u001B[1;32m    442\u001B[0m dim_names \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m(dim_coords)\n",
      "File \u001B[0;32m~/miniconda3/envs/ml-wetlands/lib/python3.8/site-packages/xarray/core/alignment.py:368\u001B[0m, in \u001B[0;36malign\u001B[0;34m(join, copy, indexes, exclude, fill_value, *objects)\u001B[0m\n\u001B[1;32m    366\u001B[0m     new_obj \u001B[38;5;241m=\u001B[39m obj\u001B[38;5;241m.\u001B[39mcopy(deep\u001B[38;5;241m=\u001B[39mcopy)\n\u001B[1;32m    367\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 368\u001B[0m     new_obj \u001B[38;5;241m=\u001B[39m \u001B[43mobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreindex\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    369\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfill_value\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfill_value\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindexers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalid_indexers\u001B[49m\n\u001B[1;32m    370\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    371\u001B[0m new_obj\u001B[38;5;241m.\u001B[39mencoding \u001B[38;5;241m=\u001B[39m obj\u001B[38;5;241m.\u001B[39mencoding\n\u001B[1;32m    372\u001B[0m result\u001B[38;5;241m.\u001B[39mappend(new_obj)\n",
      "File \u001B[0;32m~/miniconda3/envs/ml-wetlands/lib/python3.8/site-packages/xarray/core/dataset.py:2948\u001B[0m, in \u001B[0;36mDataset.reindex\u001B[0;34m(self, indexers, method, tolerance, copy, fill_value, **indexers_kwargs)\u001B[0m\n\u001B[1;32m   2744\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mreindex\u001B[39m(\n\u001B[1;32m   2745\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   2746\u001B[0m     indexers: Mapping[Any, Any] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   2751\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mindexers_kwargs: Any,\n\u001B[1;32m   2752\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Dataset:\n\u001B[1;32m   2753\u001B[0m     \u001B[38;5;124;03m\"\"\"Conform this object onto a new set of indexes, filling in\u001B[39;00m\n\u001B[1;32m   2754\u001B[0m \u001B[38;5;124;03m    missing values with ``fill_value``. The default fill value is NaN.\u001B[39;00m\n\u001B[1;32m   2755\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   2946\u001B[0m \n\u001B[1;32m   2947\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 2948\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_reindex\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2949\u001B[0m \u001B[43m        \u001B[49m\u001B[43mindexers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2950\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2951\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtolerance\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2952\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcopy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2953\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfill_value\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2954\u001B[0m \u001B[43m        \u001B[49m\u001B[43msparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m   2955\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mindexers_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2956\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/ml-wetlands/lib/python3.8/site-packages/xarray/core/dataset.py:2977\u001B[0m, in \u001B[0;36mDataset._reindex\u001B[0;34m(self, indexers, method, tolerance, copy, fill_value, sparse, **indexers_kwargs)\u001B[0m\n\u001B[1;32m   2974\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m bad_dims:\n\u001B[1;32m   2975\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minvalid reindex dimensions: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mbad_dims\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m-> 2977\u001B[0m variables, indexes \u001B[38;5;241m=\u001B[39m \u001B[43malignment\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreindex_variables\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2978\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvariables\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2979\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msizes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2980\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mxindexes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2981\u001B[0m \u001B[43m    \u001B[49m\u001B[43mindexers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2982\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2983\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtolerance\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2984\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2985\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfill_value\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfill_value\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2986\u001B[0m \u001B[43m    \u001B[49m\u001B[43msparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msparse\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2987\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2988\u001B[0m coord_names \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_coord_names)\n\u001B[1;32m   2989\u001B[0m coord_names\u001B[38;5;241m.\u001B[39mupdate(indexers)\n",
      "File \u001B[0;32m~/miniconda3/envs/ml-wetlands/lib/python3.8/site-packages/xarray/core/alignment.py:639\u001B[0m, in \u001B[0;36mreindex_variables\u001B[0;34m(variables, sizes, indexes, indexers, method, tolerance, copy, fill_value, sparse)\u001B[0m\n\u001B[1;32m    636\u001B[0m needs_masking \u001B[38;5;241m=\u001B[39m \u001B[38;5;28many\u001B[39m(d \u001B[38;5;129;01min\u001B[39;00m masked_dims \u001B[38;5;28;01mfor\u001B[39;00m d \u001B[38;5;129;01min\u001B[39;00m var\u001B[38;5;241m.\u001B[39mdims)\n\u001B[1;32m    638\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m needs_masking:\n\u001B[0;32m--> 639\u001B[0m     new_var \u001B[38;5;241m=\u001B[39m \u001B[43mvar\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_getitem_with_mask\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfill_value\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfill_value_\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    640\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mall\u001B[39m(is_full_slice(k) \u001B[38;5;28;01mfor\u001B[39;00m k \u001B[38;5;129;01min\u001B[39;00m key):\n\u001B[1;32m    641\u001B[0m     \u001B[38;5;66;03m# no reindexing necessary\u001B[39;00m\n\u001B[1;32m    642\u001B[0m     \u001B[38;5;66;03m# here we need to manually deal with copying data, since\u001B[39;00m\n\u001B[1;32m    643\u001B[0m     \u001B[38;5;66;03m# we neither created a new ndarray nor used fancy indexing\u001B[39;00m\n\u001B[1;32m    644\u001B[0m     new_var \u001B[38;5;241m=\u001B[39m var\u001B[38;5;241m.\u001B[39mcopy(deep\u001B[38;5;241m=\u001B[39mcopy)\n",
      "File \u001B[0;32m~/miniconda3/envs/ml-wetlands/lib/python3.8/site-packages/xarray/core/variable.py:812\u001B[0m, in \u001B[0;36mVariable._getitem_with_mask\u001B[0;34m(self, key, fill_value)\u001B[0m\n\u001B[1;32m    809\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    810\u001B[0m     actual_indexer \u001B[38;5;241m=\u001B[39m indexer\n\u001B[0;32m--> 812\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[43mas_indexable\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_data\u001B[49m\u001B[43m)\u001B[49m\u001B[43m[\u001B[49m\u001B[43mactual_indexer\u001B[49m\u001B[43m]\u001B[49m\n\u001B[1;32m    813\u001B[0m mask \u001B[38;5;241m=\u001B[39m indexing\u001B[38;5;241m.\u001B[39mcreate_mask(indexer, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mshape, data)\n\u001B[1;32m    814\u001B[0m \u001B[38;5;66;03m# we need to invert the mask in order to pass data first. This helps\u001B[39;00m\n\u001B[1;32m    815\u001B[0m \u001B[38;5;66;03m# pint to choose the correct unit\u001B[39;00m\n\u001B[1;32m    816\u001B[0m \u001B[38;5;66;03m# TODO: revert after https://github.com/hgrecco/pint/issues/1019 is fixed\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/ml-wetlands/lib/python3.8/site-packages/xarray/core/indexing.py:1161\u001B[0m, in \u001B[0;36mNumpyIndexingAdapter.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   1159\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__getitem__\u001B[39m(\u001B[38;5;28mself\u001B[39m, key):\n\u001B[1;32m   1160\u001B[0m     array, key \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_indexing_array_and_key(key)\n\u001B[0;32m-> 1161\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43marray\u001B[49m\u001B[43m[\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m]\u001B[49m\n",
      "\u001B[0;31mMemoryError\u001B[0m: Unable to allocate 94.8 GiB for an array with shape (161203, 157857) and data type float32"
     ]
    }
   ],
   "source": [
    "from xarray import Dataset\n",
    "from rattlinbog.data_group import group_datasets, GroupByRois\n",
    "from rattlinbog.transforms import Compose, ClipRoi, ConcatTimeSeries, ClipValues, CoarsenAvgSpatially, RoundToInt16, \\\n",
    "    StoreAsNetCDF, NameDatasets, EatMyData\n",
    "\n",
    "S1_2021_100m_OUT = Path(\"/shared/sentinel-1/roi/100m\")\n",
    "\n",
    "\n",
    "def ds_namer(ds: Dataset) -> str:\n",
    "    time_str = ds.attrs['time'].strftime(DATE_FORMAT)\n",
    "    roi_name = ds.attrs['roi'].name.replace(' ', '_')\n",
    "    return f\"{time_str}_{roi_name}\"\n",
    "\n",
    "\n",
    "transformation_pipeline = Compose([ClipRoi(),\n",
    "                                   ClipValues(vmin=0, vmax=200),\n",
    "                                   CoarsenAvgSpatially(stride=10),\n",
    "                                   ConcatTimeSeries(),\n",
    "                                   RoundToInt16(),\n",
    "                                   NameDatasets(ds_namer),\n",
    "                                   StoreAsNetCDF(S1_2021_100m_OUT),\n",
    "                                   EatMyData()])\n",
    "group = group_datasets(vh_datasets, by_rule=GroupByRois(ramsar_rois))\n",
    "group = transformation_pipeline(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"transform successful\")\n",
    "group"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}