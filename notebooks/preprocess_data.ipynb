{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "This notebook handles, preprocessing of raw data which is to be used for training and validating models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Preprocess Sentinel-1 Data\n",
    "\n",
    "Query the Sentinel-1 Data buckets:\n",
    " - Query S3 storage for general area and time of interest\n",
    " - Clip to region of interests (wetlands)\n",
    " - Clamp values to reduce noise  - data investigation determined a range of [0, 200]\n",
    " - Coarsen raster data so our models don't get too big - no GPUs atm\n",
    " - Save as int16 -> sufficient precision as we raw data is stored in int16 as well, and we don't add info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Load S1-Datasets and Ramsar Geometry\n",
    "\n",
    "Load the S1 datasets in the time and region of interest as well as the Ramsar shape files containing the geometry of the wetlands.\n",
    "\n",
    "**NOTE:** We use VH for now, as the reduced noise should help training machine learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from rattlinbog.loaders import load_s1_datasets_from_file_list, load_rois, DATE_FORMAT\n",
    "\n",
    "S1_2021_AT_FILE_LIST = Path(\"/shared/sentinel-1/paths-west-AT-2021.txt\")\n",
    "RAMSAR_SHAPE_FILE = Path(\"/shared/ramsar/RAMSAR_AT_01.shp\")\n",
    "\n",
    "vh_datasets = load_s1_datasets_from_file_list(S1_2021_AT_FILE_LIST, bands={'VH'})\n",
    "ramsar_rois = load_rois(RAMSAR_SHAPE_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Sentinel-1 data reduction\n",
    "\n",
    "To apply our models efficiently we want to reduce the data\n",
    "- Clip to our specific Ramsar regions of interest\n",
    "- Clamp data to reduce noise\n",
    "- Coarsen the resolution - speeding up training of machine learning models and reducing noise\n",
    "- Round to int16 - this precision should be sufficient\n",
    "- Stream to shared disk for further usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transform successful\n"
     ]
    }
   ],
   "source": [
    "from xarray import Dataset\n",
    "from rattlinbog.data_group import group_datasets, GroupByRois\n",
    "from rattlinbog.transforms import Compose, ClipRoi, ConcatTimeSeries, ClipValues, CoarsenAvgSpatially, RoundToInt16, \\\n",
    "    StoreAsNetCDF, NameDatasets, EatMyData, SortByTime, ChunkGroup\n",
    "\n",
    "S1_2021_100m_OUT = Path(\"/shared/sentinel-1/roi/100m\")\n",
    "\n",
    "\n",
    "def ds_namer(ds: Dataset) -> str:\n",
    "    from_ts = ds.attrs['from_ts'].strftime(DATE_FORMAT)\n",
    "    to_ts = ds.attrs['to_ts'].strftime(DATE_FORMAT)\n",
    "    roi_name = ds.attrs['roi'].name.replace(' ', '_')\n",
    "    return f\"{roi_name}_{from_ts}_to_{to_ts}\"\n",
    "\n",
    "\n",
    "group = group_datasets(vh_datasets, by_rule=GroupByRois(ramsar_rois))\n",
    "chunk_pipline = Compose([SortByTime(), ChunkGroup(16)])\n",
    "chunked_groups = chunk_pipline(group)\n",
    "\n",
    "stream_roi_pipeline = Compose([ClipRoi(),\n",
    "                               ClipValues(vmin=0, vmax=200),\n",
    "                               CoarsenAvgSpatially(stride=10),\n",
    "                               ConcatTimeSeries(),\n",
    "                               RoundToInt16(),\n",
    "                               NameDatasets(ds_namer),\n",
    "                               StoreAsNetCDF(S1_2021_100m_OUT),\n",
    "                               EatMyData()])\n",
    "\n",
    "for grp in chunked_groups:\n",
    "    stream_roi_pipeline(grp)\n",
    "\n",
    "print(\"transform successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"transform successful\")\n",
    "group"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
